{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Graph Neural Network (GNN) Training for Medical Predictions**\n",
    "\n",
    "## **Introduction**\n",
    "This notebook details the end-to-end process of training a **Graph Neural Network (GNN)** for predicting medical conditions. The model learns **patient relationships and medical histories** by leveraging graph-based learning.  \n",
    "\n",
    "We use **PyTorch Geometric (PyG)** for graph construction and **TF-IDF** for patient condition embeddings. The dataset consists of **FHIR-based structured patient records**, which we preprocess before training the model.\n",
    "\n",
    "---\n",
    "\n",
    "## **List of Contents**\n",
    "This notebook is structured into **8 key sections**, covering data extraction, preprocessing, model training, and deployment.\n",
    "\n",
    "### [**1. Extracting FHIR JSON Data (FHIR Extraction)**](#1-extracting-fhir-json-data-fhir-extraction)\n",
    "   **Keywords**: `load_json`, `extract_patients`, `extract_family_member_history`, `extract_related_person`, `extract_conditions`\n",
    "   - Extract **patient details, family medical history, relationships, and conditions** from FHIR JSON files.\n",
    "   - Convert the raw JSON data into **structured Pandas DataFrames** for further processing.\n",
    "\n",
    "### [**2. Preprocessing and Training DataFrame Creation**](#2-preprocessing-and-training-dataframe-creation)\n",
    "   **Keywords**: `df_training`, `df_patient`, `df_fmh`, `df_rp`, `df_condition`\n",
    "   - Merge **patient data** with medical conditions.\n",
    "   - Encode **family member relationships** as features.\n",
    "   - Define **multi-label classification labels** from patient conditions.\n",
    "   - Prevent **data leakage** by removing disease names from condition descriptions.\n",
    "\n",
    "### [**3. Constructing Graph Data (Graph Preparation)**](#3-constructing-graph-data-graph-preparation)\n",
    "   **Keywords**: `patient_id_map`, `edge_index`, `torch.tensor`, `Data(x=node_features, edge_index=edge_index)`\n",
    "   - Represent **patients as nodes** in the GNN.\n",
    "   - Use **TF-IDF** to generate **node features** from medical condition descriptions.\n",
    "   - Construct **edges** based on patient relationships from **RelatedPerson** data.\n",
    "\n",
    "### [**4. Train-Test Splitting for Model Training (Iterative Train-Test Split)**](#4-train-test-splitting-for-model-training-iterative-train-test-split)\n",
    "   **Keywords**: `iterative_train_test_split`, `X_train`, `Y_train`, `X_val`, `Y_val`\n",
    "   - Use **iterative train-test split** to ensure balanced label distribution.\n",
    "   - Split the data into **training (80%)** and **validation (20%)** sets.\n",
    "   - Convert features and labels into **PyTorch tensors** for compatibility with GNN models.\n",
    "\n",
    "### [**5. Graph Construction for Training and Validation**](#5-graph-construction-for-training-and-validation)\n",
    "   **Keywords**: `train_graph`, `val_graph`, `graph.clone()`\n",
    "   - Create **two separate graphs**:\n",
    "     - **Training Graph (`train_graph`)** for model training.\n",
    "     - **Validation Graph (`val_graph`)** for model evaluation.\n",
    "   - Maintain the **same edge connections** but update **node features** according to the data split.\n",
    "\n",
    "### [**6. GNN Model Definition**](#6-gnn-model-definition)\n",
    "   **Keywords**: `class GNNModel`, `GCNConv`, `F.relu`\n",
    "   - Define a **Graph Neural Network (GNN)** model using `torch_geometric.nn.GCNConv`.\n",
    "   - Implement **two graph convolution layers**:\n",
    "     - First layer transforms input features (`in_channels â†’ hidden_channels`).\n",
    "     - Second layer maps hidden representations to the target labels (`hidden_channels â†’ out_channels`).\n",
    "   - Apply **ReLU activation** for non-linearity.\n",
    "\n",
    "### [**7. Model Training with Validation**](#7-model-training-with-validation)\n",
    "   **Keywords**: `loss_fn`, `optimizer`, `loss_train`, `loss_val`\n",
    "   - Train the model using:\n",
    "     - **Adam optimizer** for weight updates.\n",
    "     - **Binary Cross-Entropy Loss (`BCEWithLogitsLoss`)** for multi-label classification.\n",
    "   - Perform **forward and backward propagation** on `train_graph`.\n",
    "   - Evaluate model performance on `val_graph` after each epoch.\n",
    "   - Print **training loss and validation loss** every 10 epochs.\n",
    "\n",
    "### [**8. Model and Vectorizer Saving**](#8-model-and-vectorizer-saving)\n",
    "   **Keywords**: `torch.save`, `pickle.dump`\n",
    "   - Save the trained **GNN model weights** (`gnn_model_weights.pt`).\n",
    "   - Save the **TF-IDF vectorizer** (`tfidf.pkl`) for use in inference.\n",
    "\n",
    "---\n",
    "\n",
    "## **Installation Requirements**\n",
    "To run this notebook, install the required dependencies using:\n",
    "\n",
    "```bash\n",
    "pip install torch torch-geometric scikit-learn fastapi hypercorn numpy pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extracting FHIR JSON Data (FHIR Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ========================\n",
    "# Helper Functions\n",
    "# ========================\n",
    "\n",
    "def extract_id(ref):\n",
    "    \"\"\"Extracts the ID from a reference string.\"\"\"\n",
    "    if ref.startswith(\"Patient/\"):\n",
    "        return ref.split(\"/\")[-1]\n",
    "    elif ref.startswith(\"RelatedPerson/\"):\n",
    "        return ref.split(\"/\")[-1]\n",
    "    elif ref.startswith(\"urn:uuid:\"):\n",
    "        return ref.split(\":\")[-1]\n",
    "    else:\n",
    "        return ref\n",
    "\n",
    "def load_json(filepath):\n",
    "    \"\"\"Loads a JSON file and returns its content.\"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_as_csv(data, output_filepath):\n",
    "    \"\"\"Saves data as a CSV file.\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "    print(f\"CSV saved at {output_filepath}\")\n",
    "\n",
    "def save_as_json(data, output_filepath):\n",
    "    \"\"\"Saves data as a JSON file.\"\"\"\n",
    "    with open(output_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"JSON saved at {output_filepath}\")\n",
    "\n",
    "# ========================\n",
    "# Extraction Functions for Each Resource\n",
    "# ========================\n",
    "\n",
    "def extract_patients(data):\n",
    "    \"\"\"Extracts patient information including ID, birth date, gender, and name.\"\"\"\n",
    "    extracted = []\n",
    "    for p in data:\n",
    "        extracted.append({\n",
    "            \"patient_id\": p.get(\"id\", \"\"),\n",
    "            \"birthDate\": p.get(\"birthDate\", \"\"),\n",
    "            \"gender\": p.get(\"gender\", \"\"),\n",
    "            \"name\": p.get(\"name\", [{\"family\": \"Unknown\"}])[0].get(\"family\", \"Unknown\")\n",
    "        })\n",
    "    return extracted\n",
    "\n",
    "def extract_family_member_history(data):\n",
    "    \"\"\"Extracts family medical history, including patient ID, relationship type, and conditions.\"\"\"\n",
    "    extracted = []\n",
    "    for rec in data:\n",
    "        patient_ref = rec.get(\"patient\", {}).get(\"reference\", \"\")\n",
    "        patient_id = extract_id(patient_ref)\n",
    "\n",
    "        # Extract relationship type if available\n",
    "        relationship = \"\"\n",
    "        if \"relationship\" in rec and \"coding\" in rec[\"relationship\"] and rec[\"relationship\"][\"coding\"]:\n",
    "            relationship = rec[\"relationship\"][\"coding\"][0].get(\"display\", \"\")\n",
    "\n",
    "        # Extract medical conditions if available\n",
    "        conditions = []\n",
    "        if \"condition\" in rec:\n",
    "            for cond in rec[\"condition\"]:\n",
    "                cond_text = cond.get(\"code\", {}).get(\"text\", \"\")\n",
    "                if cond_text:\n",
    "                    conditions.append(cond_text)\n",
    "\n",
    "        extracted.append({\n",
    "            \"family_member_history_id\": rec.get(\"id\", \"\"),\n",
    "            \"patient_id\": patient_id,\n",
    "            \"relationship\": relationship,\n",
    "            \"conditions\": \"; \".join(conditions)  # Concatenates conditions if multiple exist\n",
    "        })\n",
    "    return extracted\n",
    "\n",
    "def extract_related_person(data):\n",
    "    \"\"\"Extracts related person details including ID, relationship, name, gender, and birth date.\"\"\"\n",
    "    extracted = []\n",
    "    for rec in data:\n",
    "        patient_ref = rec.get(\"patient\", {}).get(\"reference\", \"\")\n",
    "        patient_id = extract_id(patient_ref)\n",
    "\n",
    "        # Extract and concatenate relationship descriptions if multiple exist\n",
    "        relationship = \", \".join([r.get(\"text\", \"\") for r in rec.get(\"relationship\", [])])\n",
    "\n",
    "        # Extract related person's name if available\n",
    "        rp_name = \"\"\n",
    "        if \"name\" in rec and isinstance(rec[\"name\"], list) and len(rec[\"name\"]) > 0:\n",
    "            rp_name = rec[\"name\"][0].get(\"family\", \"\")\n",
    "\n",
    "        extracted.append({\n",
    "            \"related_person_id\": extract_id(rec.get(\"id\", \"\")),\n",
    "            \"patient_id\": patient_id,\n",
    "            \"relationship\": relationship,\n",
    "            \"rp_name\": rp_name,\n",
    "            \"gender\": rec.get(\"gender\", \"\"),\n",
    "            \"birthDate\": rec.get(\"birthDate\", \"\")\n",
    "        })\n",
    "    return extracted\n",
    "\n",
    "def extract_conditions(data):\n",
    "    \"\"\"Extracts medical conditions associated with patients.\"\"\"\n",
    "    extracted = []\n",
    "    for rec in data:\n",
    "        subject_ref = rec.get(\"subject\", {}).get(\"reference\", \"\")\n",
    "        patient_id = extract_id(subject_ref)\n",
    "        disease = rec.get(\"code\", {}).get(\"text\", \"\")\n",
    "\n",
    "        extracted.append({\n",
    "            \"condition_id\": rec.get(\"id\", \"\"),\n",
    "            \"patient_id\": patient_id,\n",
    "            \"disease\": disease\n",
    "        })\n",
    "    return extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Memproses Patient dari synthea/output/processed/Patient.json\n",
      "âœ… Dataframe Patient memiliki shape: (108, 4)\n",
      "ðŸ“‚ Memproses FamilyMemberHistory dari synthea/output/processed/FamilyMemberHistory.json\n",
      "âœ… Dataframe FamilyMemberHistory memiliki shape: (193, 4)\n",
      "ðŸ“‚ Memproses RelatedPerson dari synthea/output/processed/RelatedPerson.json\n",
      "âœ… Dataframe RelatedPerson memiliki shape: (261, 6)\n",
      "ðŸ“‚ Memproses Condition dari synthea/output/processed/Condition.json\n",
      "âœ… Dataframe Condition memiliki shape: (4093, 3)\n",
      "\n",
      "Contoh DataFrame untuk Patient:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>female</td>\n",
       "      <td>Runolfsdottir785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d4f1d88b-aecc-493e-2977-44a72e0de2d9</td>\n",
       "      <td>2002-11-28</td>\n",
       "      <td>female</td>\n",
       "      <td>Jerde200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9f7675c1-1f29-10ac-92e5-8aaf367f05c3</td>\n",
       "      <td>2007-06-07</td>\n",
       "      <td>female</td>\n",
       "      <td>Sanford861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>839e461d-9a4d-a110-1fe9-97bd16378bfd</td>\n",
       "      <td>2008-05-28</td>\n",
       "      <td>male</td>\n",
       "      <td>Ruecker817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7e101445-eafd-cd17-0e6b-57f85baa3f44</td>\n",
       "      <td>1985-10-07</td>\n",
       "      <td>female</td>\n",
       "      <td>Kerluke267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             patient_id   birthDate  gender              name\n",
       "0  7da148be-b73e-73e3-ed5c-67d7c712a253  2010-05-07  female  Runolfsdottir785\n",
       "1  d4f1d88b-aecc-493e-2977-44a72e0de2d9  2002-11-28  female          Jerde200\n",
       "2  9f7675c1-1f29-10ac-92e5-8aaf367f05c3  2007-06-07  female        Sanford861\n",
       "3  839e461d-9a4d-a110-1fe9-97bd16378bfd  2008-05-28    male        Ruecker817\n",
       "4  7e101445-eafd-cd17-0e6b-57f85baa3f44  1985-10-07  female        Kerluke267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contoh DataFrame untuk FamilyMemberHistory:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_member_history_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>relationship</th>\n",
       "      <th>conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family-3a644dcd-672c-9579-cdeb-65ce6783da97-</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Father</td>\n",
       "      <td>Asthma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family-8463087b-be64-1139-b779-97d09881e034-</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Sister</td>\n",
       "      <td>Hypertension; Heart Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>family-00a4d481-551d-9741-dd8f-fa88fe29ab79-</td>\n",
       "      <td>d4f1d88b-aecc-493e-2977-44a72e0de2d9</td>\n",
       "      <td>Father</td>\n",
       "      <td>Hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>family-8c97920a-fc41-8150-f54e-9dcfc1f48fef-</td>\n",
       "      <td>d4f1d88b-aecc-493e-2977-44a72e0de2d9</td>\n",
       "      <td>Mother</td>\n",
       "      <td>Diabetes; Hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family-2b27a9c6-3b32-83fe-c4eb-ff271de3536b-</td>\n",
       "      <td>9f7675c1-1f29-10ac-92e5-8aaf367f05c3</td>\n",
       "      <td>Father</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       family_member_history_id  \\\n",
       "0  family-3a644dcd-672c-9579-cdeb-65ce6783da97-   \n",
       "1  family-8463087b-be64-1139-b779-97d09881e034-   \n",
       "2  family-00a4d481-551d-9741-dd8f-fa88fe29ab79-   \n",
       "3  family-8c97920a-fc41-8150-f54e-9dcfc1f48fef-   \n",
       "4  family-2b27a9c6-3b32-83fe-c4eb-ff271de3536b-   \n",
       "\n",
       "                             patient_id relationship  \\\n",
       "0  7da148be-b73e-73e3-ed5c-67d7c712a253       Father   \n",
       "1  7da148be-b73e-73e3-ed5c-67d7c712a253       Sister   \n",
       "2  d4f1d88b-aecc-493e-2977-44a72e0de2d9       Father   \n",
       "3  d4f1d88b-aecc-493e-2977-44a72e0de2d9       Mother   \n",
       "4  9f7675c1-1f29-10ac-92e5-8aaf367f05c3       Father   \n",
       "\n",
       "                    conditions  \n",
       "0                       Asthma  \n",
       "1  Hypertension; Heart Disease  \n",
       "2                 Hypertension  \n",
       "3       Diabetes; Hypertension  \n",
       "4                       Cancer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contoh DataFrame untuk RelatedPerson:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related_person_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>relationship</th>\n",
       "      <th>rp_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3a644dcd-672c-9579-cdeb-65ce6783da97</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Father</td>\n",
       "      <td>Barton704</td>\n",
       "      <td>female</td>\n",
       "      <td>1975-09-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67ed8fab-19a2-40c5-e56c-3dfdab2c9805</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Mother</td>\n",
       "      <td>Schowalter414</td>\n",
       "      <td>male</td>\n",
       "      <td>1989-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8463087b-be64-1139-b779-97d09881e034</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Sister</td>\n",
       "      <td>Boyle917</td>\n",
       "      <td>male</td>\n",
       "      <td>1965-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a4d481-551d-9741-dd8f-fa88fe29ab79</td>\n",
       "      <td>d4f1d88b-aecc-493e-2977-44a72e0de2d9</td>\n",
       "      <td>Father</td>\n",
       "      <td>Bernhard322</td>\n",
       "      <td>female</td>\n",
       "      <td>1968-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8c97920a-fc41-8150-f54e-9dcfc1f48fef</td>\n",
       "      <td>d4f1d88b-aecc-493e-2977-44a72e0de2d9</td>\n",
       "      <td>Mother</td>\n",
       "      <td>Jerde200</td>\n",
       "      <td>female</td>\n",
       "      <td>2003-10-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      related_person_id                            patient_id  \\\n",
       "0  3a644dcd-672c-9579-cdeb-65ce6783da97  7da148be-b73e-73e3-ed5c-67d7c712a253   \n",
       "1  67ed8fab-19a2-40c5-e56c-3dfdab2c9805  7da148be-b73e-73e3-ed5c-67d7c712a253   \n",
       "2  8463087b-be64-1139-b779-97d09881e034  7da148be-b73e-73e3-ed5c-67d7c712a253   \n",
       "3  00a4d481-551d-9741-dd8f-fa88fe29ab79  d4f1d88b-aecc-493e-2977-44a72e0de2d9   \n",
       "4  8c97920a-fc41-8150-f54e-9dcfc1f48fef  d4f1d88b-aecc-493e-2977-44a72e0de2d9   \n",
       "\n",
       "  relationship        rp_name  gender   birthDate  \n",
       "0       Father      Barton704  female  1975-09-20  \n",
       "1       Mother  Schowalter414    male  1989-02-23  \n",
       "2       Sister       Boyle917    male  1965-09-03  \n",
       "3       Father    Bernhard322  female  1968-08-26  \n",
       "4       Mother       Jerde200  female  2003-10-06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contoh DataFrame untuk Condition:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ded1426d-62e2-77ad-0c8b-5b34075c89a9</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Medication review due (situation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40f951b4-d966-312a-c6b2-2b9b89ca5f30</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Medication review due (situation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa6822b6-d4e2-bbe9-d4fa-574aac5c27ca</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Gingivitis (disorder)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35aac9a9-f1fe-8563-79d0-d279208f9098</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Medication review due (situation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63b4c19c-4488-56fe-e4eb-f5dd262aa4b2</td>\n",
       "      <td>7da148be-b73e-73e3-ed5c-67d7c712a253</td>\n",
       "      <td>Medication review due (situation)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           condition_id                            patient_id  \\\n",
       "0  ded1426d-62e2-77ad-0c8b-5b34075c89a9  7da148be-b73e-73e3-ed5c-67d7c712a253   \n",
       "1  40f951b4-d966-312a-c6b2-2b9b89ca5f30  7da148be-b73e-73e3-ed5c-67d7c712a253   \n",
       "2  aa6822b6-d4e2-bbe9-d4fa-574aac5c27ca  7da148be-b73e-73e3-ed5c-67d7c712a253   \n",
       "3  35aac9a9-f1fe-8563-79d0-d279208f9098  7da148be-b73e-73e3-ed5c-67d7c712a253   \n",
       "4  63b4c19c-4488-56fe-e4eb-f5dd262aa4b2  7da148be-b73e-73e3-ed5c-67d7c712a253   \n",
       "\n",
       "                             disease  \n",
       "0  Medication review due (situation)  \n",
       "1  Medication review due (situation)  \n",
       "2              Gingivitis (disorder)  \n",
       "3  Medication review due (situation)  \n",
       "4  Medication review due (situation)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing processed FHIR data\n",
    "processed_folder = \"synthea/output/processed/\"\n",
    "\n",
    "# Resources considered useful for predictive modeling\n",
    "resources = [\"Patient\", \"FamilyMemberHistory\", \"RelatedPerson\", \"Condition\"]\n",
    "\n",
    "# Mapping of resources to corresponding extraction functions\n",
    "extraction_functions = {\n",
    "    \"Patient\": extract_patients,\n",
    "    \"FamilyMemberHistory\": extract_family_member_history,\n",
    "    \"RelatedPerson\": extract_related_person,\n",
    "    \"Condition\": extract_conditions\n",
    "}\n",
    "\n",
    "# Dictionary to store extracted DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "for res in resources:\n",
    "    filepath = os.path.join(processed_folder, f\"{res}.json\")\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Processing {res} from {filepath}\")\n",
    "        data = load_json(filepath)\n",
    "\n",
    "        # Convert dictionary to list if necessary\n",
    "        if isinstance(data, dict):\n",
    "            data = [data]\n",
    "\n",
    "        extracted_data = extraction_functions[res](data)\n",
    "        df = pd.DataFrame(extracted_data)\n",
    "        dataframes[res] = df\n",
    "        print(f\"DataFrame for {res} created with shape: {df.shape}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"File {res}.json not found in {processed_folder}\")\n",
    "\n",
    "# Display sample rows from each DataFrame\n",
    "for res, df in dataframes.items():\n",
    "    print(f\"\\nSample DataFrame for {res}:\")\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing and Training DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# === 1. Load Data ===\n",
    "df_patient = dataframes[\"Patient\"]\n",
    "df_fmh = dataframes[\"FamilyMemberHistory\"]\n",
    "df_rp = dataframes[\"RelatedPerson\"]\n",
    "df_condition = dataframes[\"Condition\"]\n",
    "\n",
    "# === 2. Group Condition by patient_id and concatenate disease names ===\n",
    "df_condition_grouped = (\n",
    "    df_condition.groupby(\"patient_id\")[\"disease\"]\n",
    "    .apply(lambda x: \" \".join(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"disease\": \"patient_conditions_text\"})\n",
    ")\n",
    "\n",
    "# Merge df_patient with patient conditions\n",
    "df_training = pd.merge(df_patient, df_condition_grouped, on=\"patient_id\", how=\"left\").fillna(\"\")\n",
    "\n",
    "# === 3. Process FamilyMemberHistory & RelatedPerson as additional features ===\n",
    "\n",
    "# Process FamilyMemberHistory\n",
    "df_fmh_grouped = (\n",
    "    df_fmh.groupby([\"patient_id\", \"relationship\"])[\"conditions\"]\n",
    "    .apply(lambda x: \"; \".join(x.dropna().unique()))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_fmh_pivot = df_fmh_grouped.pivot(index=\"patient_id\", columns=\"relationship\", values=\"conditions\").reset_index()\n",
    "df_fmh_pivot = df_fmh_pivot.rename(columns=lambda x: x.lower() + \"_condition\" if x != \"patient_id\" else x)\n",
    "df_training = pd.merge(df_training, df_fmh_pivot, on=\"patient_id\", how=\"left\").fillna(\"\")\n",
    "\n",
    "# Process RelatedPerson\n",
    "df_rp_condition = pd.merge(df_rp, df_condition_grouped, left_on=\"related_person_id\", right_on=\"patient_id\", how=\"left\")\n",
    "df_rp_condition.drop(columns=[\"patient_id_y\"], inplace=True)\n",
    "\n",
    "df_rp_grouped = (\n",
    "    df_rp_condition.groupby([\"patient_id_x\", \"relationship\"])[\"patient_conditions_text\"]\n",
    "    .apply(lambda x: \"; \".join(x.dropna().unique()))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_rp_pivot = df_rp_grouped.pivot(index=\"patient_id_x\", columns=\"relationship\", values=\"patient_conditions_text\").reset_index()\n",
    "df_rp_pivot = df_rp_pivot.rename(columns=lambda x: x.lower() + \"_related_condition\" if x != \"patient_id_x\" else x)\n",
    "df_training = pd.merge(df_training, df_rp_pivot, left_on=\"patient_id\", right_on=\"patient_id_x\", how=\"left\").fillna(\"\")\n",
    "\n",
    "# === 4. Create Multi-Label Targets for Each Patient ===\n",
    "target_diseases = [\"Diabetes\", \"Hypertension\", \"Cancer\", \"Heart Disease\", \"Alzheimer\", \"Asthma\"]\n",
    "\n",
    "for disease in target_diseases:\n",
    "    df_training[disease] = df_training[\"patient_conditions_text\"].apply(lambda x: 1 if disease.lower() in str(x).lower() else 0)\n",
    "\n",
    "# === 5. Remove Disease Names from Text Features to Prevent Data Leakage ===\n",
    "def remove_target_diseases_partial(text, target_diseases, remove_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Removes disease names from text for a subset of patients (default 50%) \n",
    "    to simulate real-world scenarios where information may be incomplete.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Randomly determine if diseases should be removed\n",
    "    if random.random() > remove_ratio:  # Keep diseases for 50% of cases\n",
    "        return text\n",
    "\n",
    "    text = text.lower()\n",
    "    for disease in target_diseases:\n",
    "        pattern = r\"\\b\\w*\" + re.escape(disease.lower()) + r\"\\w*\\b\"\n",
    "        text = re.sub(pattern, \"\", text).strip()\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "# Apply the disease removal function to patient conditions\n",
    "df_training[\"patient_conditions_text_cleaned\"] = df_training[\"patient_conditions_text\"].apply(\n",
    "    lambda x: remove_target_diseases_partial(x, target_diseases, remove_ratio=0.5)\n",
    ")\n",
    "\n",
    "# === 6. Create Node Representations with TF-IDF ===\n",
    "text_columns = [\n",
    "    \"patient_conditions_text_cleaned\",\n",
    "]\n",
    "\n",
    "# Concatenate all text features\n",
    "df_training[\"all_text\"] = df_training[text_columns].apply(lambda x: \" \".join(x.dropna()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Constructing Graph Data (Graph Preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Graph PyG Sukses Dibuat!\n",
      "Data(x=[108, 304], edge_index=[2, 261])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = tfidf.fit_transform(df_training[\"all_text\"])\n",
    "\n",
    "# Map patient_id to a unique index\n",
    "patient_ids = df_training[\"patient_id\"].tolist()\n",
    "patient_id_map = {pid: i for i, pid in enumerate(patient_ids)}\n",
    "\n",
    "# === 7. Construct Graph Edges from RelatedPerson Relationships ===\n",
    "edge_index = []\n",
    "for _, row in df_rp.iterrows():\n",
    "    if row[\"patient_id\"] in patient_id_map and row[\"related_person_id\"] in patient_id_map:\n",
    "        edge_index.append([patient_id_map[row[\"patient_id\"]], patient_id_map[row[\"related_person_id\"]]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).T  # Convert to PyTorch Geometric format\n",
    "\n",
    "# === 8. Create PyTorch Geometric Graph ===\n",
    "node_features = torch.tensor(X_tfidf.toarray(), dtype=torch.float32)\n",
    "graph = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# === 9. Convert Labels to Tensor ===\n",
    "labels_tensor = torch.tensor(df_training[target_diseases].values, dtype=torch.float32)\n",
    "\n",
    "print(\"Graph successfully created.\")\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train-Test Splitting for Model Training (Iterative Train-Test Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Iterative Train-Test Split (Train-Validation) ===\n",
    "X = node_features.numpy()  # Konversi node features ke NumPy Array\n",
    "Y = labels_tensor.numpy()  # Konversi label ke NumPy Array\n",
    "\n",
    "# 80% Train, 20% Validation menggunakan Iterative Stratification\n",
    "X_train, Y_train, X_val, Y_val = iterative_train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# Konversi kembali ke Tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "Y_val_tensor = torch.tensor(Y_val, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Buat Graph untuk Train & Validation ===\n",
    "train_graph = graph.clone()\n",
    "train_graph.x = X_train_tensor\n",
    "train_graph.edge_index = graph.edge_index\n",
    "\n",
    "val_graph = graph.clone()\n",
    "val_graph.x = X_val_tensor\n",
    "val_graph.edge_index = graph.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. GNN Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# === Define the GNN Model ===\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initializes a Graph Convolutional Network (GCN) model.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Number of input features per node.\n",
    "            hidden_dim (int): Number of hidden layer neurons.\n",
    "            output_dim (int): Number of output classes (multi-label classification).\n",
    "        \"\"\"\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass through the GNN model.\n",
    "\n",
    "        Args:\n",
    "            data (torch_geometric.data.Data): Graph data containing node features and edge indices.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output logits for each node.\n",
    "        \"\"\"\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)  # Activation function\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Initialize the GNN Model ===\n",
    "hidden_dim = 64  # Number of hidden layer neurons\n",
    "output_dim = len(target_diseases)  # Number of output labels for multi-label classification\n",
    "\n",
    "# Initialize the model with input features, hidden layer, and output labels\n",
    "model = GNNModel(input_dim=node_features.shape[1], hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "\n",
    "# Define the optimizer (Adam optimizer with a learning rate of 0.01)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the loss function (Binary Cross-Entropy with Logits for multi-label classification)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model Training with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7068\n",
      "Epoch 10, Loss: 0.5781\n",
      "Epoch 20, Loss: 0.5556\n",
      "Epoch 30, Loss: 0.5335\n",
      "Epoch 40, Loss: 0.5067\n",
      "Epoch 50, Loss: 0.4792\n",
      "Epoch 60, Loss: 0.4518\n",
      "Epoch 70, Loss: 0.4245\n",
      "âœ… Model GNN selesai dilatih!\n"
     ]
    }
   ],
   "source": [
    "# === Train the GNN Model with Validation ===\n",
    "num_epochs = 75  # Number of training epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass on training data\n",
    "    logits_train = model(train_graph)  \n",
    "    loss_train = loss_fn(logits_train, Y_train_tensor)  # Compute training loss\n",
    "    \n",
    "    # Backpropagation and optimization step\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation step\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        logits_val = model(val_graph)\n",
    "        loss_val = loss_fn(logits_val, Y_val_tensor)  # Compute validation loss\n",
    "\n",
    "    # Print training and validation loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {loss_train.item():.4f}, Val Loss: {loss_val.item():.4f}\")\n",
    "\n",
    "print(\"GNN model training completed with validation set!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model and Vectorizer Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bobot model GNN berhasil disimpan ke 'gnn_model_weights.pt'!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Save the trained GNN model weights\n",
    "torch.save(model.state_dict(), \"gnn_model_weights.pt\")\n",
    "print(\"GNN model weights saved to 'gnn_model_weights.pt'.\")\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open(\"tfidf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "print(\"TF-IDF vectorizer saved to 'tfidf.pkl'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
